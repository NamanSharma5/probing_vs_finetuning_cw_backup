{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJAj8P5r8i3m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "from pytorch_lightning import LightningModule, LightningDataModule, Trainer, seed_everything\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
        "from torchmetrics.functional import auroc\n",
        "from PIL import Image\n",
        "from medmnist.info import INFO\n",
        "from medmnist.dataset import MedMNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL7v3hY78i3n"
      },
      "source": [
        "We will be using the [MedMNIST Pneumonia](https://medmnist.com/) dataset, which is a medical imaging inspired dataset but with the characteristics of MNIST. This allows efficient experimentation due to the small image size. The dataset contains real chest X-ray images but downsampled to 28 x 28 pixels, with binary labels indicating the presence of [Pneumonia](https://www.nhs.uk/conditions/pneumonia/) (which is an inflammation of the lungs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WpnXKjrm0bL"
      },
      "outputs": [],
      "source": [
        "class SimCLRPneumoniaMNISTDataset(MedMNIST):\n",
        "    def __init__(self, split = 'train', positive_pair = True):\n",
        "        ''' Dataset class for PneumoniaMNIST.\n",
        "        The provided init function will automatically download the necessary\n",
        "        files at the first class initialistion.\n",
        "\n",
        "        :param split: 'train', 'val' or 'test', select subset\n",
        "\n",
        "        '''\n",
        "        self.flag = \"pneumoniamnist\"\n",
        "        self.size = 28\n",
        "        self.size_flag = \"\"\n",
        "        self.root = './data/coursework/'\n",
        "        self.info = INFO[self.flag]\n",
        "        self.download()\n",
        "        self.positive_pair = positive_pair\n",
        "\n",
        "        npz_file = np.load(os.path.join(self.root, \"pneumoniamnist.npz\"))\n",
        "\n",
        "        self.split = split\n",
        "\n",
        "        # Load all the images\n",
        "        assert self.split in ['train','val','test']\n",
        "\n",
        "        self.imgs = npz_file[f'{self.split}_images']\n",
        "        self.labels = npz_file[f'{self.split}_labels']\n",
        "\n",
        "        # Add a short description in plain language.\n",
        "        # We know that for self supervised learning we need to create two views of the same image, but these should be hard to learn from with a variety of relevant augmentations applied\n",
        "\n",
        "        # The original SimCLR paper use RandomCrop with Resize, Random Horizontal Flip, Random Color Distortion and Random Gaussian Blur.\n",
        "        # As MedMNIST is grayscale, we don't need RandomColor Distortion.\n",
        "        \n",
        "        # From inspecting a sample of the training images (see below), we have the following observations which we will use to design our augmentation pipeline:\n",
        "        # 1. The images all have the heart on the same side (this can lead to overfitting) -> we can apply random horizontal flips to account for left/right orientation variation\n",
        "        # 2. The orientation in terms of rotation or angle of the sternum is not always the same (in reality patient positioning in front of the x-ray can vary) -> we can apply random rotations to account for this\n",
        "        # 3. We see some images are more zoomed in than others but only a few , hence we do some random resized cropping to create more images with different zoom levels \n",
        "        # 4. From online research, we learn that pneumonia can be in one or both lungs and it can be in patches or spread out (lobar or Bronchopneumonia)-> hence we also do random crop/ resize to account for this variation  \n",
        "        # 5. We also see a variation in the bluriness of the images, hence we apply gaussian blur to account for this variation\n",
        "\n",
        "        # We started with the default random resized crop scale of (0.08,1) but we found this was generating views that were too small (basically whole view was single colour), hence we increased this to 0.2\n",
        "        self.augmentation_pipeline = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.RandomResizedCrop(size=28,scale=(0.2,1.0)),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
        "            transforms.RandomAffine(degrees=10, translate=(0.1, 0.1))\n",
        "        ])\n",
        "        \n",
        "        \n",
        "    def __len__(self):    \n",
        "        return self.imgs.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # of shape [1, 28, 28], img_view1 and img_view2, representing two augmented view of the images.\n",
        "        if not self.positive_pair:\n",
        "            # return indexed image\n",
        "\n",
        "            return self.imgs[index], self.labels[index]\n",
        "\n",
        "        img = self.imgs[index]\n",
        "\n",
        "        img1 = self.augmentation_pipeline(img)\n",
        "        img2 = self.augmentation_pipeline(img)      \n",
        "\n",
        "        return img1, img2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQTVOXwESOGL"
      },
      "outputs": [],
      "source": [
        "class SimCLRPneumoniaMNISTDataModule(LightningDataModule):\n",
        "    def __init__(self, batch_size: int = 8):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.train_set = SimCLRPneumoniaMNISTDataset(split='train')\n",
        "        self.val_set = SimCLRPneumoniaMNISTDataset(split='val')\n",
        "        self.test_set = SimCLRPneumoniaMNISTDataset(split='test')\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(dataset=self.train_set, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(dataset=self.val_set, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(dataset=self.test_set, batch_size=self.batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxDF8J8CSOGL"
      },
      "source": [
        "#### **Check** dataset implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbV-xhDitmrR"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialise data module\n",
        "datamodule = SimCLRPneumoniaMNISTDataModule()\n",
        "# Get train dataloader\n",
        "train_dataloader = datamodule.train_dataloader()\n",
        "# Get first batch\n",
        "batch = next(iter(train_dataloader))\n",
        "# Visualise the images\n",
        "view1, view2 = batch\n",
        "f, ax = plt.subplots(2, 8, figsize=(12,4))\n",
        "for i in range(8):\n",
        "  ax[0,i].imshow(view1[i, 0], cmap='gray')\n",
        "  ax[1,i].imshow(view2[i, 0], cmap='gray')\n",
        "  ax[0,i].set_title('view 1')\n",
        "  ax[1,i].set_title('view 2')\n",
        "  ax[0, i].axis(\"off\")\n",
        "  ax[1, i].axis(\"off\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
