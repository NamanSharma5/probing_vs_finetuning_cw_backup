{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJAj8P5r8i3m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "from pytorch_lightning import LightningModule, LightningDataModule, Trainer, seed_everything\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
        "from torchmetrics.functional import auroc\n",
        "from PIL import Image\n",
        "from medmnist.info import INFO\n",
        "from medmnist.dataset import MedMNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL7v3hY78i3n"
      },
      "source": [
        "We will be using the [MedMNIST Pneumonia](https://medmnist.com/) dataset, which is a medical imaging inspired dataset but with the characteristics of MNIST. This allows efficient experimentation due to the small image size. The dataset contains real chest X-ray images but downsampled to 28 x 28 pixels, with binary labels indicating the presence of [Pneumonia](https://www.nhs.uk/conditions/pneumonia/) (which is an inflammation of the lungs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WpnXKjrm0bL"
      },
      "outputs": [],
      "source": [
        "class SimCLRPneumoniaMNISTDataset(MedMNIST):\n",
        "    def __init__(self, split = 'train', positive_pair = True):\n",
        "        ''' Dataset class for PneumoniaMNIST.\n",
        "        The provided init function will automatically download the necessary\n",
        "        files at the first class initialistion.\n",
        "\n",
        "        :param split: 'train', 'val' or 'test', select subset\n",
        "\n",
        "        '''\n",
        "        self.flag = \"pneumoniamnist\"\n",
        "        self.size = 28\n",
        "        self.size_flag = \"\"\n",
        "        self.root = './data/coursework/'\n",
        "        self.info = INFO[self.flag]\n",
        "        self.download()\n",
        "        self.positive_pair = positive_pair\n",
        "\n",
        "        npz_file = np.load(os.path.join(self.root, \"pneumoniamnist.npz\"))\n",
        "\n",
        "        self.split = split\n",
        "\n",
        "        # Load all the images\n",
        "        assert self.split in ['train','val','test']\n",
        "\n",
        "        self.imgs = npz_file[f'{self.split}_images']\n",
        "        self.labels = npz_file[f'{self.split}_labels']\n",
        "\n",
        "        # Add a short description in plain language.\n",
        "        # We know that for self supervised learning we need to create two views of the same image, but these should be hard to learn from with a variety of relevant augmentations applied\n",
        "\n",
        "        # The original SimCLR paper use RandomCrop with Resize, Random Horizontal Flip, Random Color Distortion and Random Gaussian Blur.\n",
        "        # As MedMNIST is grayscale, we don't need RandomColor Distortion.\n",
        "        \n",
        "        # From inspecting a sample of the training images (see below), we have the following observations which we will use to design our augmentation pipeline:\n",
        "        # 1. The images all have the heart on the same side (this can lead to overfitting) -> we can apply random horizontal flips to account for left/right orientation variation\n",
        "        # 2. The orientation in terms of rotation or angle of the sternum is not always the same (in reality patient positioning in front of the x-ray can vary) -> we can apply random rotations to account for this\n",
        "        # 3. We see some images are more zoomed in than others but only a few , hence we do some random resized cropping to create more images with different zoom levels \n",
        "        # 4. From online research, we learn that pneumonia can be in one or both lungs and it can be in patches or spread out (lobar or Bronchopneumonia)-> hence we also do random crop/ resize to account for this variation  \n",
        "        # 5. We also see a variation in the bluriness of the images, hence we apply gaussian blur to account for this variation\n",
        "\n",
        "        # We started with the default random resized crop scale of (0.08,1) but we found this was generating views that were too small (basically whole view was single colour), hence we increased this to 0.2\n",
        "        self.augmentation_pipeline = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.RandomResizedCrop(size=28,scale=(0.2,1.0)),\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),\n",
        "            transforms.RandomAffine(degrees=10, translate=(0.1, 0.1))\n",
        "        ])\n",
        "        \n",
        "        \n",
        "    def __len__(self):    \n",
        "        return self.imgs.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # of shape [1, 28, 28], img_view1 and img_view2, representing two augmented view of the images.\n",
        "        if not self.positive_pair:\n",
        "            # return indexed image\n",
        "\n",
        "            return self.imgs[index], self.labels[index]\n",
        "\n",
        "        img = self.imgs[index]\n",
        "\n",
        "        img1 = self.augmentation_pipeline(img)\n",
        "        img2 = self.augmentation_pipeline(img)      \n",
        "\n",
        "        return img1, img2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQTVOXwESOGL"
      },
      "outputs": [],
      "source": [
        "class SimCLRPneumoniaMNISTDataModule(LightningDataModule):\n",
        "    def __init__(self, batch_size: int = 8):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.train_set = SimCLRPneumoniaMNISTDataset(split='train')\n",
        "        self.val_set = SimCLRPneumoniaMNISTDataset(split='val')\n",
        "        self.test_set = SimCLRPneumoniaMNISTDataset(split='test')\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(dataset=self.train_set, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(dataset=self.val_set, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(dataset=self.test_set, batch_size=self.batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxDF8J8CSOGL"
      },
      "source": [
        "#### **Check** dataset implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbV-xhDitmrR"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Initialise data module\n",
        "datamodule = SimCLRPneumoniaMNISTDataModule()\n",
        "# Get train dataloader\n",
        "train_dataloader = datamodule.train_dataloader()\n",
        "# Get first batch\n",
        "batch = next(iter(train_dataloader))\n",
        "# Visualise the images\n",
        "view1, view2 = batch\n",
        "f, ax = plt.subplots(2, 8, figsize=(12,4))\n",
        "for i in range(8):\n",
        "  ax[0,i].imshow(view1[i, 0], cmap='gray')\n",
        "  ax[1,i].imshow(view2[i, 0], cmap='gray')\n",
        "  ax[0,i].set_title('view 1')\n",
        "  ax[1,i].set_title('view 2')\n",
        "  ax[0, i].axis(\"off\")\n",
        "  ax[1, i].axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "implement the simclr loss function based on the paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def simclr_loss(embedding_view1, embedding_view2, tau=1.0):\n",
        "    '''\n",
        "    Corrected implementation of the SimCLR loss function.\n",
        "    '''\n",
        "    # Step 1: Normalise the embeddings\n",
        "    embedding_view1_norm = F.normalize(embedding_view1, p=2, dim=1)\n",
        "    embedding_view2_norm = F.normalize(embedding_view2, p=2, dim=1)\n",
        "    \n",
        "    # Step 2: gather all embeddings into one big vector of size [2*N , feature_dim]\n",
        "    combined_embeddings = torch.cat([embedding_view1_norm, embedding_view2_norm], dim=0)\n",
        "    \n",
        "    # Step 3: compute all possible similarities, should be a matrix of size [2 * N, 2 * N]\n",
        "    # all_similarities[i,j] will be the similarity between z_all_views[i] and z_all_views[j].\n",
        "    # Use the hint.\n",
        "    # all_similarities = torch.mm(embedding_view1_normalised, embedding_view2_normalised.t())  \n",
        "    # we need to use combined similarities since we index i, j+N, i+N,j\n",
        "    similarity_matrix = torch.mm(combined_embeddings, combined_embeddings.T)\n",
        "    \n",
        "    batch_size = embedding_view1.size(0)\n",
        "    n = similarity_matrix.size(0) // 2\n",
        "\n",
        "    # Step 4: self-mask. For computing the denominator term in the loss function,\n",
        "    # we need to sum over all possible similarities except the self-similarity.\n",
        "    # Create a mask of shape [2*N, 2*N] that is 1 for all valid pairs and 0 for all self-pairs (i = j).\n",
        "    \n",
        "    # we needs 1 in all values apart from diagonal\n",
        "\n",
        "    self_mask = torch.ones((2 * n, 2 * n), dtype=torch.bool).to(embedding_view1.device)\n",
        "    self_mask.fill_diagonal_(0)\n",
        "\n",
        "    # Step 5: Here we want to return a mask of size[2 * N, 2* N] for which mask[i,j] = 1 if\n",
        "    # z_all_views[i] and z_all_views[j] form a positive pair.\n",
        "    # There should be exactely 2 * N non-zeros elements in this matrix.\n",
        "    \n",
        "    # positive pairs are where i,j+N and i+N,j, use these for the mask\n",
        "    positive_mask = torch.zeros_like(self_mask)\n",
        "    for i in range(batch_size):\n",
        "        positive_mask[i, i+batch_size] = 1\n",
        "        positive_mask[i+batch_size, i] = 1\n",
        " \n",
        "    assert(positive_mask.sum() == 2 * n)\n",
        "\n",
        "    # Step 6: Computing all numerators for the loss function.\n",
        "    # Should be vector of size [2 * N],\n",
        "    # where element is exp(sim(i, j) / t) for each positive pair (i, j).\n",
        "    # Re-use the computed quantities above.\n",
        "    \n",
        "    # we need to use the mask to get the positive pairs\n",
        "    sim_ij = torch.masked_select(similarity_matrix, positive_mask)\n",
        "\n",
        "    exp_sim_ij = torch.exp(sim_ij / tau)\n",
        "    assert(exp_sim_ij.shape[0] == 2 * n)\n",
        "\n",
        "    \n",
        "    # Step 7: Computing all denominators for the loss function.\n",
        "    # Should be a vector of size [2 * N].\n",
        "    # Where each element should be the sum of exp(sim(i,k)/tau) for all k != i.\n",
        "    \n",
        "    # we need to use the self mask to get the sum of all similarities apart from the self similarity\n",
        "    sim_ik = torch.masked_select(similarity_matrix, self_mask)\n",
        "    exp_sim_ik = torch.exp(sim_ik / tau).view(2*batch_size, -1).sum(dim=1)  # Sum over all negative samples\n",
        "    assert(exp_sim_ik.shape[0] == 2 * n)\n",
        "\n",
        "\n",
        "    loss_ij = -torch.log(exp_sim_ij / exp_sim_ik)\n",
        "    loss = loss_ij.mean()  # Average over all positive pairs\n",
        "    \n",
        "    return loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "testing to ensure correct behaviour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DO NOT MODIFY THIS CELL! IT IS FOR CHECKING THE IMPLEMENTATION ONLY.\n",
        "\n",
        "seed_everything(33)\n",
        "\n",
        "expected_results = [torch.tensor(1.7518), torch.tensor(1.6376), torch.tensor(4.194),  torch.tensor(4.1754)]\n",
        "for i, (N, feature_dim) in enumerate(zip([3, 3, 33, 33], [5, 125, 5, 125])):\n",
        "  print(f\"{N=} and {feature_dim=}\")\n",
        "  embedding_view1 = torch.rand((N, feature_dim))\n",
        "  embedding_view2 = torch.rand((N, feature_dim))\n",
        "  loss = simclr_loss(embedding_view1.clone(), embedding_view2.clone(), tau=0.5)\n",
        "  print(f\"Expected loss: {expected_results[i]}, Computed loss: {loss}\")\n",
        "  assert torch.isclose(loss, expected_results[i], rtol=1e-3)\n",
        "print(\"Passed all tests successfully !\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "implement a CNN backbone using a contrastive loss objective"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ImageEncoder(torch.nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "        self.net = models.resnet50(weights=None)\n",
        "        del self.net.fc\n",
        "        self.net.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.net.conv1(x)\n",
        "        x = self.net.bn1(x)\n",
        "        x = self.net.relu(x)\n",
        "        x0 = self.net.maxpool(x)\n",
        "        x1 = self.net.layer1(x0)\n",
        "        x2 = self.net.layer2(x1)\n",
        "        x3 = self.net.layer3(x2)\n",
        "        x4 = self.net.layer4(x3)\n",
        "        x4 = self.net.avgpool(x4)\n",
        "        x4 = torch.flatten(x4, 1)\n",
        "        return x4\n",
        "    \n",
        "    \n",
        "class SimCLRModel(LightningModule):\n",
        "    def __init__(self, learning_rate: float = 0.001):\n",
        "        super().__init__()\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        self.encoder = ImageEncoder()\n",
        "\n",
        "        self.projector = torch.nn.Sequential(\n",
        "            torch.nn.Linear(2048, 1024),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(1024, 128),\n",
        "        )\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer\n",
        "\n",
        "    def process_batch(self, batch):\n",
        "        # TASK: Implement the process_batch function\n",
        "        self.encoder.train()\n",
        "        self.projector.train()\n",
        "\n",
        "        # print device of model and data\n",
        "        # print(f\"{self.device=}\")\n",
        "\n",
        "        # put the data on the same device as the encoder and projector\n",
        "\n",
        "        view1, view2 = batch\n",
        "        view1 = view1.to(device=self.device)\n",
        "        view2 = view2.to(device=self.device)\n",
        "\n",
        "\n",
        "        # Pass the views through the encoder\n",
        "        embedding_view1 = self.encoder(view1)\n",
        "        embedding_view2 = self.encoder(view2)\n",
        "\n",
        "        # Pass the embeddings through the projector\n",
        "        projection_view1 = self.projector(embedding_view1)\n",
        "        projection_view2 = self.projector(embedding_view2)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = simclr_loss(projection_view1, projection_view2)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss = self.process_batch(batch)\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        if batch_idx == 0:\n",
        "            grid = torchvision.utils.make_grid(torch.cat((batch[0][0:4, ...], batch[1][0:4, ...]), dim=0), nrow=4, normalize=True)\n",
        "            self.logger.experiment.add_image('train_images', grid, self.global_step)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss = self.process_batch(batch)\n",
        "        self.log('val_loss', loss, prog_bar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train the model using the provided data module\n",
        "seed_everything(33, workers=True)\n",
        "\n",
        "data = SimCLRPneumoniaMNISTDataModule(batch_size=32)\n",
        "\n",
        "model = SimCLRModel()\n",
        "\n",
        "trainer = Trainer(\n",
        "    max_epochs=5,\n",
        "    accelerator='auto',\n",
        "    devices=1,\n",
        "    logger=TensorBoardLogger(save_dir='./lightning_logs/coursework/', name='simclr'),\n",
        "    callbacks=[ModelCheckpoint(monitor='val_loss', mode='min'), TQDMProgressBar(refresh_rate=10)],\n",
        ")\n",
        "trainer.fit(model=model, datamodule=data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "compare two encoders, one fine-tuned vs one probed on image classification task of the PneumoniaMNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PneumoniaMNISTDataset(MedMNIST):\n",
        "    def __init__(self, split = 'train', augmentation: bool = False):\n",
        "        ''' Dataset class for Pneumonia MNST.\n",
        "        The provided init function will automatically download the necessary\n",
        "        files at the first class initialistion.\n",
        "\n",
        "        :param split: 'train', 'val' or 'test', select subset\n",
        "\n",
        "        '''\n",
        "        self.flag = \"pneumoniamnist\"\n",
        "        self.size = 28\n",
        "        self.size_flag = \"\"\n",
        "        self.root = './data/coursework/'\n",
        "        self.info = INFO[self.flag]\n",
        "        self.download()\n",
        "\n",
        "        npz_file = np.load(os.path.join(self.root, \"pneumoniamnist.npz\"))\n",
        "\n",
        "        self.split = split\n",
        "\n",
        "        # Load all the images\n",
        "        assert self.split in ['train','val','test']\n",
        "\n",
        "        self.imgs = npz_file[f'{self.split}_images']\n",
        "        self.labels = npz_file[f'{self.split}_labels']\n",
        "\n",
        "        self.do_augment = augmentation\n",
        "\n",
        "        # TASK: Define here your data augmentation pipeline suitable for classification.\n",
        "        # Check previous tutorials for inspiration.\n",
        "        \n",
        "        # SimCLR emphasizes aggressive augmentations to create pairs that maintain core semantic similarity despite heavy alterations. \n",
        "        # However for image classification you want the model to focus on discriminative features and be robust to minor real-world variations\n",
        "        # but you typically don't want transformations so strong that they change the essential nature of the class\n",
        "\n",
        "\n",
        "        if self.do_augment:\n",
        "            self.augmentation_pipeline = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.RandomResizedCrop(size=28,scale=(0.7,1.0)), # made crop scale bigger to 0.7\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 1.0)), # reduced blurring\n",
        "                transforms.RandomAffine(degrees=5, translate=(0.1, 0.1)) # reduced variation\n",
        "            ])\n",
        "            \n",
        "            \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.imgs.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # TASK: Implement the __getitem__ function to return the image and its class label.\n",
        "        label = self.labels[index]\n",
        "        img = self.imgs[index]\n",
        "        if self.do_augment:\n",
        "            img = self.augmentation_pipeline(img)\n",
        "        else:\n",
        "            img = transforms.ToTensor()(img)\n",
        "        return img, label[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PneumoniaMNISTDataModule(LightningDataModule):\n",
        "    def __init__(self, batch_size: int = 32):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.train_set = PneumoniaMNISTDataset(split='train', augmentation=True)\n",
        "        self.val_set = PneumoniaMNISTDataset(split='val', augmentation=False)\n",
        "        self.test_set = PneumoniaMNISTDataset(split='test', augmentation=False)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(dataset=self.train_set, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(dataset=self.val_set, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(dataset=self.test_set, batch_size=self.batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DO NOT MODIFY THIS CELL! IT IS FOR CHECKING THE IMPLEMENTATION ONLY.\n",
        "\n",
        "# Initialise data module\n",
        "datamodule = PneumoniaMNISTDataModule()\n",
        "# Get train dataloader\n",
        "train_dataloader = datamodule.train_dataloader()\n",
        "# Get first batch\n",
        "batch = next(iter(train_dataloader))\n",
        "# Visualise the images\n",
        "images, labels = batch\n",
        "f, ax = plt.subplots(1, 8, figsize=(12,4))\n",
        "for i in range(8):\n",
        "  ax[i].imshow(images[i, 0], cmap='gray')\n",
        "  ax[i].set_title('label: ' + str(labels[i].item()))\n",
        "  ax[i].axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "using a pre-trained encoder as a starting point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_encoder_from_checkpoint(checkpoint_path):\n",
        "  ckpt = torch.load(checkpoint_path, map_location='cpu')\n",
        "  simclr_module = SimCLRModel()\n",
        "  print(simclr_module.load_state_dict(state_dict=ckpt))\n",
        "  return simclr_module.encoder.eval()\n",
        "\n",
        "imagenet_model = '../data/coursework/model_imagenet.ckpt'\n",
        "chestxray_model = '../data/coursework/model_chestxray.ckpt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from typing import Any\n",
        "\n",
        "\n",
        "class ImageClassifier(LightningModule):\n",
        "    def __init__(self, pretrained_encoder: torch.nn.Module, freeze_encoder: bool = True, output_dim: int = 2, learning_rate: float = 0.001):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.encoder = pretrained_encoder\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        if freeze_encoder:\n",
        "            for param in self.encoder.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        # Get encoder output dimension \n",
        "        self.classifier = nn.Linear(2048, output_dim) # got image encoder output dimension from previous cell (where we printed the output shape of the encoder)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.encoder(x)\n",
        "        output = self.classifier(features)\n",
        "        return F.sigmoid(output)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        logits = self(x)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch,batch_idx):\n",
        "        x, y = batch\n",
        "        y_hot = F.one_hot(y.long(),2)\n",
        "        logits = self(x)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "        roc_auc = auroc(logits, y_hot,task=\"binary\", num_classes=self.hparams.output_dim, average='macro')\n",
        "        self.log('val_loss', loss, prog_bar=True)\n",
        "        self.log('val_roc_auc', roc_auc, prog_bar=True)\n",
        "        \n",
        "        # return batch loss and roc_auc\n",
        "        return loss, roc_auc\n",
        "    \n",
        "    def test_step(self, batch,batch_idx):\n",
        "        x, y = batch\n",
        "        y_hot = F.one_hot(y.long(),2)\n",
        "        logits = self(x)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "        roc_auc = auroc(logits, y_hot,task=\"binary\", num_classes=self.hparams.output_dim, average='macro')\n",
        "        self.log('test_loss', loss, prog_bar=True)\n",
        "        self.log('test_roc_auc', roc_auc, prog_bar=True)\n",
        "        \n",
        "        # return batch loss and roc_auc\n",
        "        return loss, roc_auc\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "start by finetuning the encoder "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "seed_everything(33, workers=True)\n",
        "\n",
        "data = PneumoniaMNISTDataModule(batch_size=32)\n",
        "\n",
        "# TASK: Implement the model finetuning training and testing routines.\n",
        "\n",
        "# IMAGENET\n",
        "imagenet_encoder = load_encoder_from_checkpoint(imagenet_model)\n",
        "finetuned_imagenet_model = ImageClassifier(pretrained_encoder=imagenet_encoder, freeze_encoder=False, output_dim=2, learning_rate=0.001)\n",
        "trainer = Trainer(\n",
        "    max_epochs=25,\n",
        "    accelerator='auto',\n",
        "    devices=1,\n",
        "    logger=TensorBoardLogger(save_dir='./lightning_logs/coursework/', name='simclr'),\n",
        "    callbacks=[ModelCheckpoint(monitor='val_loss', mode='min'), TQDMProgressBar(refresh_rate=10)],\n",
        ")\n",
        "trainer.fit(model=finetuned_imagenet_model, datamodule=data)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
